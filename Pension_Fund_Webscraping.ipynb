{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pension_Fund_Webscraping.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGoTh3NUxHlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup as BS\n",
        "from pandas import ExcelWriter\n",
        "from urllib.request import urlopen\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def make_soup(url):\n",
        "    \"\"\"\n",
        "    soup function which returns the html code \n",
        "    of the specific page as a soup object.\n",
        "    it takes the desired url as input\n",
        "\n",
        "    \"\"\"\n",
        "  thepage = urllib.request.urlopen(url)\n",
        "  soupdata = BeautifulSoup(thepage, \"html.parser\")\n",
        "  return soupdata\n",
        "\n",
        "\n",
        "# List of Test States which updates the URL\n",
        "state_List = ['NJ','WA','WV','WI','NY']\n",
        "\n",
        "Pf_Dict = {}\n",
        "for state in state_List:\n",
        "  # This is the website with the Pf data,change as necessary\n",
        "  soup = make_soup(\"https://publicplansdata.org/quick-facts/by-state/state/?state=\"+state)\n",
        "\n",
        "  # In my case I am interested in tables,adjust as needed\n",
        "  table = soup.find('table')\n",
        "  # Get header object of the table\n",
        "  t_h = [th.text for th in table.find_all('th')]\n",
        "  # Tablerow object\n",
        "  tablerows = table.find_all('tr')\n",
        "\n",
        "  Colu = []\n",
        "  Fd_list = []\n",
        "  # Loop through the tablerow object\n",
        "  for each_r in tablerows:\n",
        "    tr_d = each_r.find_all('td')\n",
        "  # Loop through the tabledata object\n",
        "    er_d = [ed.text for ed in tr_d]\n",
        "    Colu.append(er_d)\n",
        "  # Make the Pf dataframe\n",
        "  Pf_Dict[state] = pd.DataFrame(Colu)\n",
        "\n",
        "  # Set headers\n",
        "  Pf_Dict[state].columns = t_h\n",
        "\n",
        "  # Center Headers\n",
        "  pd.set_option('colheader_justify', 'center')\n",
        "  # Drop None Rows\n",
        "  Pf_Dict[state] = Pf_Dict[state].dropna()\n",
        "\n",
        "  # Keep First 2 and last columns\n",
        "  Pf_Dict[state] = Pf_Dict[state].iloc[:,[0,1,-1]]\n",
        "\n",
        "  \n",
        "  # Convert column to $Dollars\n",
        "  Pf_Dict[state]['Assets (millions)'] = ['${:,.2f}'.format(float(x.replace(',',''))) for x in Pf_Dict[state]['Assets (millions)']]\n",
        "\n",
        "# Dictionary of Pfs\n",
        "Pf_Dict\n",
        "\n",
        "writer = ExcelWriter(r\"C:\\Users\\INPUT YOUR YOUR DESTINATION FOLDER\\PFund.xlsx\",engine ='xlsxwriter')\n",
        "\n",
        "#Loop through dictionary,to convert each df to separate worksheet in same workbook\n",
        "for Pf_k, St_Pf in Pf_Dict.items():\n",
        "  Pf_Dict[Pf_k].to_excel(writer,Pf_k)\n",
        "# Save the writer object\n",
        "writer.save()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}